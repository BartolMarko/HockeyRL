dry_run: False

# Environment
n_actions: 4
opponents:
  - type: 'StrongBot'
    priority: 0.6
  - type: 'WeakBot'
    priority: 0.4
# rewards
reward_transform: "v2"
# rewards: v1
reward_scale: 2.1
closeness_to_puck_reward_weight: 1.2
puck_direction_reward_weight: 1.2
touch_puck_reward_weight: 1.2
reward_step_penalty: 0.02

# Buffers
buffer_type: "per"
buffer_max_size: 1000000

# Training
n_games: 100000
warmup_games: 200
learn_steps_per_episode: 1
batch_size: 2048
lr_actor: 0.0004
lr_critic: 0.0003
gamma: 0.99
tau: 0.005
# alpha
automatic_entropy_tuning: True
lr_alpha: 0.0005
# critic target network
target_update_freq: 1

# Network
algorithm: "sac"
hidden_size: 1024

# Evaluation
eval_freq: 300
eval_episodes: 20

# Model saving
save_model: True
save_model_freq: 400

# Logging
use_wandb: True
wandb_project: "hockey-rl"
exp_name: "v2-per-6_4-bot-pool-deeper"
resume: False
save_video: True
log_gradients: False
