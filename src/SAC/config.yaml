dry_run: False

# Environment
n_actions: 4
opponent_pool:
  type: 'weighted'
opponents:
  - type: 'StrongBot'
    priority: 0.65
  - type: 'WeakBot'
    priority: 0.35
self_play:
  - name: 'SelfPlayMgr'
    priority: 0.7
    max_pool_size: 20
    activation_type: 'botwin'
    activation_epsilon: 0.9
    pooling:
      - type: 'episode'
        freq: 80
    sampler:
      name: 'pfsp'
      pfsp_p: 0.5
num_envs: 16

# rewards
reward_transform: "v0"
still_puck_penalty: 0.1
draw_penalty: 3

# Buffers
buffer_type: "replay"
buffer_max_size: 1500000
upside_down: True

# Training
n_games: 5000
warmup_games: 300
learn_steps_per_episode: 1
batch_size: 1024
lr_actor: 0.0004
lr_critic: 0.0003
gamma: 0.99
tau: 0.005
# alpha
automatic_entropy_tuning: True
lr_alpha: 0.00025
# critic target network
target_update_freq: 1
# Explorer
explorer:
  # type: random

  # type: 'gaussian'
  # mu: 0.5
  # std_dev: 0.85

  # type: ou
  # theta: 0.25
  # sigma: 0.3

  # type: optimistic
  # beta: 1.1

  # type: curious
  # beta: 0.3
  # hidden_dim: 64
  # lr_pred: 0.001

  type: pink

# Network
algorithm: "sac"
hidden_size: 512

# Evaluation
eval_freq: 241
eval_episodes: 32

# Model saving
save_model: True
save_model_freq: 400

# Logging
use_wandb: True
wandb_project: "hockey-rl"
exp_name: "sac-v0-pink-replay-episode"
resume: False
save_video: True
log_gradients: True
