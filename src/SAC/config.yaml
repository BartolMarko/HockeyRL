dry_run: False

# Environment
n_actions: 4
opponent_pool:
  type: 'weighted'
opponents:
  - type: StrongBot
    priority: 0.2
  - type: WeakBot
    priority: 0.1
  - type: PuckFollowBot
    priority: 0.15
  - type: CustomAgent
    priority: 0.2
    experiment_name: sac-v4-pink-4-step-per
  - type: CustomAgent
    experiment_name: sac-v0-gaussian-replay-self-play-mirror
    priority: 0.2
  - type: CustomAgent
    experiment_name: sac-v4-pink-replay
    priority: 0.15
self_play:
  - name: SelfPlayMgr
    priority: 0.8
    max_pool_size: 10
    activation_type: botwin
    activation_epsilon: 0.8
    pooling:
    - type: episode
      freq: 200
    sampler:
      name: delta_uniform
      pfsp_p: 0.7
num_envs: 16
env_left_start_modes:
  - [ 'normal' ]
  - [ 'custom', 0.2, 3000 ]
  - [ 'custom', 0.8, 4500 ]
  - [ 'custom', 0.4, 7000 ]
  # - [ 'custom', 0.2, 10 ]
  # - [ 'custom', 0.8, 20 ]
  # - [ 'custom', 0.4, 30 ]

# rewards
reward_transform: "v4"
still_puck_penalty: 0.005
draw_penalty: 3

# Buffers
buffer_type: "n-step-per"
buffer_max_size: 1000000
upside_down: True
n_step_buffer_n: 6

# Training
n_games: 7500
warmup_games: 300
learn_steps_per_episode: 1
batch_size: 1024
lr_actor: 0.0004
lr_critic: 0.0003
gamma: 0.99
tau: 0.005
# alpha
automatic_entropy_tuning: True
lr_alpha: 0.00025
# critic target network
target_update_freq: 1
# Explorer
explorer:
  type: pink
# Munchausen RL
use_munchausen: False

# Network
algorithm: "sac"
hidden_size: 512

# Evaluation
eval_freq: 250
eval_episodes: 32

# Model saving
save_model: True
save_model_freq: 300

# Logging
use_wandb: True
wandb_project: "hockey-rl"
exp_name: "sac-v4-pink-6-step-per-env-schd"
resume: False
save_video: True
log_gradients: True
