dry_run: False

# Environment
n_actions: 4
weak_opponent: True

# Buffers
buffer_max_size: 1000000

# Training
n_games: 20000
warmup_games: 50
reward_scale: 2
batch_size: 256
lr_actor: 0.0003
lr_critic: 0.0003
gamma: 0.99
tau: 0.005
# alpha
automatic_entropy_tuning: True
lr_alpha: 0.001
# critic target network
target_update_freq: 1

# Network
hidden_size: 256

# Evaluation
eval_freq: 100
eval_episodes: 20

# Model saving
save_model: True
save_model_freq: 300

# Logging
use_wandb: True
wandb_project: "hockey-rl"
exp_name: "baseline-sac"
save_video: True
log_gradients: False
